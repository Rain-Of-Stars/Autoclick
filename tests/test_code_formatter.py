# -*- coding: utf-8 -*-
"""
ä»£ç æ ¼å¼åŒ–å·¥å…·ï¼šè‡ªåŠ¨ä¿®å¤å¸¸è§çš„ä»£ç è§„èŒƒé—®é¢˜
"""

import os
import re
import ast
from pathlib import Path
from typing import List, Dict, Any, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent


class CodeFormatter:
    """ä»£ç æ ¼å¼åŒ–å™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.fixes_applied = []
        self.backup_dir = project_root / 'backups'
        
        # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
        self.backup_dir.mkdir(exist_ok=True)
    
    def format_file(self, file_path: Path, create_backup: bool = True) -> Dict[str, Any]:
        """æ ¼å¼åŒ–å•ä¸ªæ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            create_backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½
        
        Returns:
            æ ¼å¼åŒ–ç»“æœ
        """
        relative_path = file_path.relative_to(self.project_root)
        
        try:
            # è¯»å–åŸæ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                original_content = f.read()
            
            # åˆ›å»ºå¤‡ä»½
            if create_backup:
                backup_path = self.backup_dir / f"{relative_path.name}.backup"
                with open(backup_path, 'w', encoding='utf-8') as f:
                    f.write(original_content)
            
            # åº”ç”¨æ ¼å¼åŒ–
            formatted_content = original_content
            fixes = []
            
            # 1. æ·»åŠ ç¼–ç å£°æ˜
            formatted_content, encoding_fix = self._add_encoding_declaration(formatted_content)
            if encoding_fix:
                fixes.append(encoding_fix)
            
            # 2. æ¸…ç†å°¾éšç©ºæ ¼
            formatted_content, whitespace_fixes = self._remove_trailing_whitespace(formatted_content)
            fixes.extend(whitespace_fixes)
            
            # 3. ä¿®å¤æ³¨é‡Šé—´è·
            formatted_content, comment_fixes = self._fix_comment_spacing(formatted_content)
            fixes.extend(comment_fixes)
            
            # 4. æ•´ç†å¯¼å…¥é¡ºåº
            formatted_content, import_fixes = self._organize_imports(formatted_content)
            fixes.extend(import_fixes)
            
            # 5. æ·»åŠ åŸºç¡€æ–‡æ¡£å­—ç¬¦ä¸²
            formatted_content, docstring_fixes = self._add_basic_docstrings(formatted_content, str(relative_path))
            fixes.extend(docstring_fixes)
            
            # å†™å…¥æ ¼å¼åŒ–åçš„å†…å®¹
            if formatted_content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(formatted_content)
            
            return {
                'file_path': str(relative_path),
                'fixes_applied': fixes,
                'fix_count': len(fixes),
                'success': True
            }
            
        except Exception as e:
            return {
                'file_path': str(relative_path),
                'fixes_applied': [],
                'fix_count': 0,
                'success': False,
                'error': str(e)
            }
    
    def _add_encoding_declaration(self, content: str) -> Tuple[str, Dict[str, Any]]:
        """æ·»åŠ ç¼–ç å£°æ˜"""
        lines = content.split('\n')
        
        # æ£€æŸ¥å‰ä¸¤è¡Œæ˜¯å¦å·²æœ‰ç¼–ç å£°æ˜
        encoding_patterns = [
            r'# -\*- coding: utf-8 -\*-',
            r'# coding: utf-8',
            r'# coding=utf-8'
        ]
        
        has_encoding = False
        for line in lines[:2]:
            for pattern in encoding_patterns:
                if re.search(pattern, line):
                    has_encoding = True
                    break
            if has_encoding:
                break
        
        if not has_encoding:
            # æ·»åŠ ç¼–ç å£°æ˜
            encoding_line = '# -*- coding: utf-8 -*-'
            
            # å¦‚æœç¬¬ä¸€è¡Œæ˜¯shebangï¼Œåœ¨ç¬¬äºŒè¡Œæ·»åŠ 
            if lines and lines[0].startswith('#!'):
                lines.insert(1, encoding_line)
            else:
                lines.insert(0, encoding_line)
            
            return '\n'.join(lines), {
                'type': 'encoding_added',
                'description': 'æ·»åŠ UTF-8ç¼–ç å£°æ˜'
            }
        
        return content, None
    
    def _remove_trailing_whitespace(self, content: str) -> Tuple[str, List[Dict[str, Any]]]:
        """ç§»é™¤å°¾éšç©ºæ ¼"""
        lines = content.split('\n')
        fixes = []
        
        for i, line in enumerate(lines):
            if line.rstrip() != line and line.strip():
                lines[i] = line.rstrip()
                fixes.append({
                    'type': 'trailing_whitespace_removed',
                    'description': f'ç§»é™¤ç¬¬{i+1}è¡Œå°¾éšç©ºæ ¼',
                    'line': i + 1
                })
        
        return '\n'.join(lines), fixes
    
    def _fix_comment_spacing(self, content: str) -> Tuple[str, List[Dict[str, Any]]]:
        """ä¿®å¤æ³¨é‡Šé—´è·"""
        lines = content.split('\n')
        fixes = []
        
        for i, line in enumerate(lines):
            # æ£€æŸ¥è¡Œå†…æ³¨é‡Šé—´è·
            if '#' in line and not line.strip().startswith('#'):
                # æŸ¥æ‰¾æ³¨é‡Šä½ç½®
                comment_pos = line.index('#')
                before_comment = line[:comment_pos]
                comment_part = line[comment_pos:]
                
                # æ£€æŸ¥æ³¨é‡Šå‰æ˜¯å¦æœ‰è¶³å¤Ÿç©ºæ ¼
                if before_comment and not before_comment.endswith('  '):
                    # ç¡®ä¿æ³¨é‡Šå‰æœ‰ä¸¤ä¸ªç©ºæ ¼
                    before_comment = before_comment.rstrip() + '  '
                    lines[i] = before_comment + comment_part
                    fixes.append({
                        'type': 'comment_spacing_fixed',
                        'description': f'ä¿®å¤ç¬¬{i+1}è¡Œæ³¨é‡Šé—´è·',
                        'line': i + 1
                    })
        
        return '\n'.join(lines), fixes
    
    def _organize_imports(self, content: str) -> Tuple[str, List[Dict[str, Any]]]:
        """æ•´ç†å¯¼å…¥é¡ºåºï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            tree = ast.parse(content)
            lines = content.split('\n')
            
            # æŸ¥æ‰¾å¯¼å…¥è¯­å¥çš„è¡Œå·
            import_lines = []
            for node in ast.walk(tree):
                if isinstance(node, (ast.Import, ast.ImportFrom)):
                    import_lines.append(node.lineno - 1)  # ASTè¡Œå·ä»1å¼€å§‹
            
            if not import_lines:
                return content, []
            
            # æå–å¯¼å…¥è¯­å¥
            imports = []
            for line_no in sorted(import_lines):
                if line_no < len(lines):
                    imports.append((line_no, lines[line_no]))
            
            # ç®€å•çš„å¯¼å…¥åˆ†ç±»å’Œæ’åº
            standard_imports = []
            third_party_imports = []
            local_imports = []
            
            standard_modules = {
                'os', 'sys', 'time', 'datetime', 'json', 'pickle', 'logging',
                'threading', 'multiprocessing', 'queue', 'collections', 'typing',
                'pathlib', 'shutil', 'subprocess', 'signal', 'warnings', 'ctypes'
            }
            
            for line_no, import_line in imports:
                # ç®€å•åˆ†ç±»
                if any(mod in import_line for mod in standard_modules):
                    standard_imports.append(import_line)
                elif any(mod in import_line for mod in ['PySide6', 'cv2', 'numpy', 'PIL']):
                    third_party_imports.append(import_line)
                else:
                    local_imports.append(import_line)
            
            # é‡æ–°ç»„ç»‡å¯¼å…¥
            organized_imports = []
            if standard_imports:
                organized_imports.extend(sorted(standard_imports))
                organized_imports.append('')  # ç©ºè¡Œåˆ†éš”
            
            if third_party_imports:
                organized_imports.extend(sorted(third_party_imports))
                organized_imports.append('')  # ç©ºè¡Œåˆ†éš”
            
            if local_imports:
                organized_imports.extend(sorted(local_imports))
                organized_imports.append('')  # ç©ºè¡Œåˆ†éš”
            
            # æ›¿æ¢åŸæœ‰å¯¼å…¥
            if organized_imports:
                # ç§»é™¤æœ€åçš„ç©ºè¡Œ
                if organized_imports and organized_imports[-1] == '':
                    organized_imports.pop()
                
                # æ‰¾åˆ°å¯¼å…¥åŒºåŸŸçš„å¼€å§‹å’Œç»“æŸ
                first_import = min(import_lines)
                last_import = max(import_lines)
                
                # æ›¿æ¢å¯¼å…¥åŒºåŸŸ
                new_lines = (lines[:first_import] + 
                           organized_imports + 
                           lines[last_import + 1:])
                
                new_content = '\n'.join(new_lines)
                
                if new_content != content:
                    return new_content, [{
                        'type': 'imports_organized',
                        'description': 'æ•´ç†å¯¼å…¥é¡ºåº'
                    }]
        
        except SyntaxError:
            pass  # è¯­æ³•é”™è¯¯æ—¶è·³è¿‡å¯¼å…¥æ•´ç†
        
        return content, []
    
    def _add_basic_docstrings(self, content: str, file_path: str) -> Tuple[str, List[Dict[str, Any]]]:
        """æ·»åŠ åŸºç¡€æ–‡æ¡£å­—ç¬¦ä¸²"""
        try:
            tree = ast.parse(content)
            lines = content.split('\n')
            fixes = []
            
            # æ£€æŸ¥æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²
            if not ast.get_docstring(tree):
                # ç”ŸæˆåŸºç¡€æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²
                module_name = Path(file_path).stem
                docstring = f'"""\n{module_name} æ¨¡å—\n\næ¨¡å—åŠŸèƒ½æè¿°\n"""'
                
                # æ‰¾åˆ°åˆé€‚çš„æ’å…¥ä½ç½®ï¼ˆç¼–ç å£°æ˜ä¹‹åï¼‰
                insert_pos = 0
                for i, line in enumerate(lines):
                    if line.strip().startswith('#') and ('coding' in line or 'encoding' in line):
                        insert_pos = i + 1
                        break
                
                lines.insert(insert_pos, docstring)
                fixes.append({
                    'type': 'module_docstring_added',
                    'description': 'æ·»åŠ æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²'
                })
            
            if fixes:
                return '\n'.join(lines), fixes
        
        except SyntaxError:
            pass
        
        return content, []
    
    def format_project(self, file_pattern: str = "*.py", 
                      exclude_patterns: List[str] = None) -> Dict[str, Any]:
        """æ ¼å¼åŒ–æ•´ä¸ªé¡¹ç›®
        
        Args:
            file_pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
            exclude_patterns: æ’é™¤æ¨¡å¼åˆ—è¡¨
        
        Returns:
            æ ¼å¼åŒ–ç»“æœ
        """
        if exclude_patterns is None:
            exclude_patterns = ['.venv', '__pycache__', '.git', 'backups']
        
        python_files = list(self.project_root.rglob(file_pattern))
        
        # è¿‡æ»¤æ’é™¤çš„æ–‡ä»¶
        filtered_files = []
        for file_path in python_files:
            if not any(pattern in str(file_path) for pattern in exclude_patterns):
                filtered_files.append(file_path)
        
        print(f"æ ¼å¼åŒ– {len(filtered_files)} ä¸ªPythonæ–‡ä»¶...")
        
        results = []
        total_fixes = 0
        
        for file_path in filtered_files:
            result = self.format_file(file_path)
            results.append(result)
            total_fixes += result['fix_count']
            
            if result['success'] and result['fix_count'] > 0:
                print(f"âœ… {result['file_path']}: {result['fix_count']} ä¸ªä¿®å¤")
            elif not result['success']:
                print(f"âŒ {result['file_path']}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        return {
            'total_files': len(filtered_files),
            'total_fixes': total_fixes,
            'successful_files': sum(1 for r in results if r['success']),
            'failed_files': sum(1 for r in results if not r['success']),
            'results': results
        }
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š"""
        report = []
        report.append("=" * 60)
        report.append("ä»£ç æ ¼å¼åŒ–æŠ¥å‘Š")
        report.append("=" * 60)
        
        report.append(f"\nğŸ“Š æ ¼å¼åŒ–ç»Ÿè®¡:")
        report.append(f"  - å¤„ç†æ–‡ä»¶æ•°: {results['total_files']}")
        report.append(f"  - æˆåŠŸæ–‡ä»¶æ•°: {results['successful_files']}")
        report.append(f"  - å¤±è´¥æ–‡ä»¶æ•°: {results['failed_files']}")
        report.append(f"  - æ€»ä¿®å¤æ•°: {results['total_fixes']}")
        
        # ä¿®å¤ç±»å‹ç»Ÿè®¡
        fix_types = {}
        for result in results['results']:
            for fix in result['fixes_applied']:
                fix_type = fix['type']
                fix_types[fix_type] = fix_types.get(fix_type, 0) + 1
        
        if fix_types:
            report.append(f"\nğŸ”§ ä¿®å¤ç±»å‹ç»Ÿè®¡:")
            for fix_type, count in sorted(fix_types.items(), key=lambda x: x[1], reverse=True):
                report.append(f"  - {fix_type}: {count}")
        
        # ä¿®å¤æœ€å¤šçš„æ–‡ä»¶
        report.append(f"\nğŸ“ ä¿®å¤æœ€å¤šçš„æ–‡ä»¶:")
        file_fixes = [(r['file_path'], r['fix_count']) for r in results['results'] if r['fix_count'] > 0]
        file_fixes.sort(key=lambda x: x[1], reverse=True)
        
        for file_path, fix_count in file_fixes[:5]:
            report.append(f"  - {file_path}: {fix_count} ä¸ªä¿®å¤")
        
        return '\n'.join(report)


def main():
    """ä¸»å‡½æ•°"""
    formatter = CodeFormatter(project_root)
    
    # æ ¼å¼åŒ–é¡¹ç›®
    results = formatter.format_project()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = formatter.generate_report(results)
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = project_root / 'tests' / 'code_formatting_report.txt'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


if __name__ == "__main__":
    main()
