# -*- coding: utf-8 -*-
"""
ä»£ç å†—ä½™åˆ†æå·¥å…·ï¼šæ£€æŸ¥é¡¹ç›®ä¸­çš„é‡å¤ä»£ç å’Œå†—ä½™å¯¼å…¥
"""

import os
import ast
import re
import hashlib
from pathlib import Path
from collections import defaultdict, Counter
from typing import Set, Dict, List, Tuple, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent


class RedundancyAnalyzer:
    """ä»£ç å†—ä½™åˆ†æå™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.function_signatures = defaultdict(list)  # å‡½æ•°ç­¾å -> æ–‡ä»¶åˆ—è¡¨
        self.code_blocks = defaultdict(list)  # ä»£ç å—å“ˆå¸Œ -> æ–‡ä»¶åˆ—è¡¨
        self.import_usage = defaultdict(set)  # æ–‡ä»¶ -> ä½¿ç”¨çš„å¯¼å…¥
        self.all_imports = defaultdict(set)  # æ–‡ä»¶ -> æ‰€æœ‰å¯¼å…¥
        self.unused_imports = defaultdict(set)  # æ–‡ä»¶ -> æœªä½¿ç”¨çš„å¯¼å…¥
        
    def analyze_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        relative_path = file_path.relative_to(self.project_root)
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æAST
            tree = ast.parse(content)
            
            # åˆ†æå‡½æ•°
            functions = self._extract_functions(tree, str(relative_path))
            
            # åˆ†æä»£ç å—
            code_blocks = self._extract_code_blocks(content, str(relative_path))
            
            # åˆ†æå¯¼å…¥ä½¿ç”¨
            imports, used_imports = self._analyze_imports(tree, content, str(relative_path))
            
            return {
                'functions': functions,
                'code_blocks': code_blocks,
                'imports': imports,
                'used_imports': used_imports
            }
            
        except Exception as e:
            print(f"è­¦å‘Šï¼šæ— æ³•åˆ†ææ–‡ä»¶ {file_path}: {e}")
            return {}
    
    def _extract_functions(self, tree: ast.AST, file_path: str) -> List[Dict[str, Any]]:
        """æå–å‡½æ•°ä¿¡æ¯"""
        functions = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # ç”Ÿæˆå‡½æ•°ç­¾å
                args = [arg.arg for arg in node.args.args]
                signature = f"{node.name}({', '.join(args)})"
                
                # è®¡ç®—å‡½æ•°ä½“å“ˆå¸Œ
                func_lines = []
                if hasattr(node, 'lineno') and hasattr(node, 'end_lineno'):
                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æå–å‡½æ•°ä½“ä»£ç 
                    body_hash = hashlib.md5(signature.encode()).hexdigest()[:8]
                else:
                    body_hash = hashlib.md5(signature.encode()).hexdigest()[:8]
                
                func_info = {
                    'name': node.name,
                    'signature': signature,
                    'body_hash': body_hash,
                    'line_start': getattr(node, 'lineno', 0),
                    'line_end': getattr(node, 'end_lineno', 0)
                }
                
                functions.append(func_info)
                self.function_signatures[signature].append(file_path)
        
        return functions
    
    def _extract_code_blocks(self, content: str, file_path: str) -> List[Dict[str, Any]]:
        """æå–ä»£ç å—ï¼ˆç”¨äºæ£€æµ‹é‡å¤ä»£ç ï¼‰"""
        lines = content.split('\n')
        blocks = []
        
        # æ£€æŸ¥è¿ç»­çš„éç©ºè¡Œç»„æˆçš„ä»£ç å—ï¼ˆè‡³å°‘3è¡Œï¼‰
        current_block = []
        for i, line in enumerate(lines):
            stripped = line.strip()
            if stripped and not stripped.startswith('#'):
                current_block.append((i + 1, stripped))
            else:
                if len(current_block) >= 3:
                    # ç”Ÿæˆä»£ç å—å“ˆå¸Œ
                    block_content = '\n'.join([line for _, line in current_block])
                    block_hash = hashlib.md5(block_content.encode()).hexdigest()[:8]
                    
                    block_info = {
                        'hash': block_hash,
                        'start_line': current_block[0][0],
                        'end_line': current_block[-1][0],
                        'line_count': len(current_block),
                        'content_preview': block_content[:100] + '...' if len(block_content) > 100 else block_content
                    }
                    
                    blocks.append(block_info)
                    self.code_blocks[block_hash].append((file_path, block_info))
                
                current_block = []
        
        return blocks
    
    def _analyze_imports(self, tree: ast.AST, content: str, file_path: str) -> Tuple[Set[str], Set[str]]:
        """åˆ†æå¯¼å…¥å’Œä½¿ç”¨æƒ…å†µ"""
        imports = set()
        used_imports = set()
        
        # æå–æ‰€æœ‰å¯¼å…¥
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    module_name = alias.name.split('.')[0]
                    imports.add(module_name)
                    
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    module_name = node.module.split('.')[0]
                    imports.add(module_name)
                    
                    # è®°å½•å…·ä½“å¯¼å…¥çš„åç§°
                    for alias in node.names:
                        imports.add(alias.name)
        
        # æ£€æŸ¥å¯¼å…¥ä½¿ç”¨ï¼ˆç®€å•çš„æ–‡æœ¬æœç´¢ï¼‰
        for imp in imports:
            # æ£€æŸ¥æ˜¯å¦åœ¨ä»£ç ä¸­ä½¿ç”¨
            if re.search(rf'\b{re.escape(imp)}\b', content):
                used_imports.add(imp)
        
        self.all_imports[file_path] = imports
        self.import_usage[file_path] = used_imports
        self.unused_imports[file_path] = imports - used_imports
        
        return imports, used_imports
    
    def detect_duplicate_functions(self) -> Dict[str, List[str]]:
        """æ£€æµ‹é‡å¤å‡½æ•°"""
        duplicates = {}
        
        for signature, files in self.function_signatures.items():
            if len(files) > 1:
                duplicates[signature] = files
        
        return duplicates
    
    def detect_duplicate_code_blocks(self) -> Dict[str, List[Tuple[str, Dict]]]:
        """æ£€æµ‹é‡å¤ä»£ç å—"""
        duplicates = {}
        
        for block_hash, occurrences in self.code_blocks.items():
            if len(occurrences) > 1:
                duplicates[block_hash] = occurrences
        
        return duplicates
    
    def detect_unused_imports(self) -> Dict[str, Set[str]]:
        """æ£€æµ‹æœªä½¿ç”¨çš„å¯¼å…¥"""
        return dict(self.unused_imports)
    
    def analyze_import_patterns(self) -> Dict[str, Any]:
        """åˆ†æå¯¼å…¥æ¨¡å¼"""
        all_imports_count = Counter()
        used_imports_count = Counter()
        
        for file_path, imports in self.all_imports.items():
            for imp in imports:
                all_imports_count[imp] += 1
        
        for file_path, used_imports in self.import_usage.items():
            for imp in used_imports:
                used_imports_count[imp] += 1
        
        # è®¡ç®—ä½¿ç”¨ç‡
        import_usage_rate = {}
        for imp, total_count in all_imports_count.items():
            used_count = used_imports_count.get(imp, 0)
            usage_rate = used_count / total_count if total_count > 0 else 0
            import_usage_rate[imp] = {
                'total_imports': total_count,
                'used_imports': used_count,
                'usage_rate': usage_rate
            }
        
        return import_usage_rate
    
    def analyze_project(self) -> Dict[str, Any]:
        """åˆ†ææ•´ä¸ªé¡¹ç›®"""
        python_files = list(self.project_root.rglob('*.py'))
        
        print(f"åˆ†æ {len(python_files)} ä¸ªPythonæ–‡ä»¶...")
        
        for file_path in python_files:
            # è·³è¿‡è™šæ‹Ÿç¯å¢ƒå’Œç¼“å­˜
            if any(part in str(file_path) for part in ['.venv', '__pycache__', '.git']):
                continue
            
            self.analyze_file(file_path)
        
        # æ£€æµ‹å„ç§å†—ä½™
        duplicate_functions = self.detect_duplicate_functions()
        duplicate_code_blocks = self.detect_duplicate_code_blocks()
        unused_imports = self.detect_unused_imports()
        import_patterns = self.analyze_import_patterns()
        
        return {
            'duplicate_functions': duplicate_functions,
            'duplicate_code_blocks': duplicate_code_blocks,
            'unused_imports': unused_imports,
            'import_patterns': import_patterns,
            'total_files': len(python_files),
            'total_functions': len(self.function_signatures),
            'total_code_blocks': len(self.code_blocks)
        }
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå†—ä½™åˆ†ææŠ¥å‘Š"""
        analysis = self.analyze_project()
        
        report = []
        report.append("=" * 60)
        report.append("ä»£ç å†—ä½™åˆ†ææŠ¥å‘Š")
        report.append("=" * 60)
        
        # é‡å¤å‡½æ•°
        report.append(f"\nğŸ”„ é‡å¤å‡½æ•°æ£€æŸ¥:")
        if analysis['duplicate_functions']:
            report.append(f"  âŒ å‘ç° {len(analysis['duplicate_functions'])} ä¸ªé‡å¤å‡½æ•°:")
            for signature, files in list(analysis['duplicate_functions'].items())[:5]:
                report.append(f"    - {signature}")
                for file in files:
                    report.append(f"      â€¢ {file}")
        else:
            report.append("  âœ… æœªå‘ç°é‡å¤å‡½æ•°")
        
        # é‡å¤ä»£ç å—
        report.append(f"\nğŸ“‹ é‡å¤ä»£ç å—æ£€æŸ¥:")
        if analysis['duplicate_code_blocks']:
            report.append(f"  âŒ å‘ç° {len(analysis['duplicate_code_blocks'])} ä¸ªé‡å¤ä»£ç å—:")
            for block_hash, occurrences in list(analysis['duplicate_code_blocks'].items())[:3]:
                report.append(f"    - ä»£ç å— {block_hash} ({len(occurrences)} å¤„é‡å¤):")
                for file_path, block_info in occurrences:
                    report.append(f"      â€¢ {file_path} (è¡Œ {block_info['start_line']}-{block_info['end_line']})")
        else:
            report.append("  âœ… æœªå‘ç°æ˜æ˜¾é‡å¤ä»£ç å—")
        
        # æœªä½¿ç”¨çš„å¯¼å…¥
        report.append(f"\nğŸ“¦ æœªä½¿ç”¨å¯¼å…¥æ£€æŸ¥:")
        total_unused = sum(len(unused) for unused in analysis['unused_imports'].values())
        if total_unused > 0:
            report.append(f"  âš ï¸  å‘ç° {total_unused} ä¸ªæœªä½¿ç”¨çš„å¯¼å…¥:")
            count = 0
            for file_path, unused in analysis['unused_imports'].items():
                if unused and count < 5:  # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
                    report.append(f"    - {file_path}: {', '.join(list(unused)[:3])}")
                    count += 1
        else:
            report.append("  âœ… æœªå‘ç°æ˜æ˜¾æœªä½¿ç”¨çš„å¯¼å…¥")
        
        # å¯¼å…¥æ¨¡å¼åˆ†æ
        report.append(f"\nğŸ“Š å¯¼å…¥ä½¿ç”¨ç‡åˆ†æ:")
        low_usage_imports = []
        for imp, stats in analysis['import_patterns'].items():
            if stats['usage_rate'] < 0.5 and stats['total_imports'] > 2:
                low_usage_imports.append((imp, stats))
        
        if low_usage_imports:
            report.append(f"  âš ï¸  ä½ä½¿ç”¨ç‡å¯¼å…¥ (ä½¿ç”¨ç‡ < 50%):")
            for imp, stats in sorted(low_usage_imports, key=lambda x: x[1]['usage_rate'])[:5]:
                report.append(f"    - {imp}: {stats['used_imports']}/{stats['total_imports']} ({stats['usage_rate']:.1%})")
        else:
            report.append("  âœ… å¯¼å…¥ä½¿ç”¨ç‡è‰¯å¥½")
        
        # ç»Ÿè®¡ä¿¡æ¯
        report.append(f"\nğŸ“Š é¡¹ç›®ç»Ÿè®¡:")
        report.append(f"  - åˆ†ææ–‡ä»¶æ•°: {analysis['total_files']}")
        report.append(f"  - å‡½æ•°æ€»æ•°: {analysis['total_functions']}")
        report.append(f"  - ä»£ç å—æ€»æ•°: {analysis['total_code_blocks']}")
        report.append(f"  - é‡å¤å‡½æ•°: {len(analysis['duplicate_functions'])}")
        report.append(f"  - é‡å¤ä»£ç å—: {len(analysis['duplicate_code_blocks'])}")
        
        return '\n'.join(report)


def main():
    """ä¸»å‡½æ•°"""
    analyzer = RedundancyAnalyzer(project_root)
    report = analyzer.generate_report()
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = project_root / 'tests' / 'redundancy_analysis_report.txt'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


if __name__ == "__main__":
    main()
